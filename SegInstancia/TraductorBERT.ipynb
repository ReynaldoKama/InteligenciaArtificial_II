{"cells":[{"metadata":{"trusted":true,"_uuid":"3ac28581fbb945c5eb8bc891284c3bfef6233782","id":"n5AF5pndMHJw","executionInfo":{"status":"ok","timestamp":1688736791825,"user_tz":240,"elapsed":5,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["%matplotlib inline"],"execution_count":1,"outputs":[]},{"metadata":{"_uuid":"16bbd6a3f1cb08b3cc4683eaa2028817cce43f27","id":"4jDTkZ50MHJx"},"cell_type":"markdown","source":["Traducción con una red de secuencia a secuencia y atención\n","==================\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"6a98cb3604f081d7148c59bcd8a7a1308ac4f7b8","colab":{"base_uri":"https://localhost:8080/"},"id":"XlEsqyFjMHJz","executionInfo":{"status":"ok","timestamp":1688736795134,"user_tz":240,"elapsed":3313,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"2afbaac6-8426-47c1-a90a-1777006571c8"},"cell_type":"code","source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"metadata":{"trusted":true,"_uuid":"0c3fb554fb79e3757add40f9c99bfb9455d96a02","colab":{"base_uri":"https://localhost:8080/"},"id":"bj_WTOzNMHJ0","executionInfo":{"status":"ok","timestamp":1688736795135,"user_tz":240,"elapsed":17,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"5f93a590-ce85-49cb-917d-495db71a1abe"},"cell_type":"code","source":["print(torch.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J2SE7QzxRpEX","executionInfo":{"status":"ok","timestamp":1688736799993,"user_tz":240,"elapsed":4869,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"449e6826-c7b8-43c3-c9e6-9642c10ec99f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"metadata":{"_uuid":"c4afa12d70a6d159fd015016819c0fc8e4dadf26","id":"sn-pBuwLMHJ0"},"cell_type":"markdown","source":["Carga de archivos de datos\n","==================\n","\n"]},{"metadata":{"_uuid":"4771b612109d0ad866baabe31fa77361025fa450","id":"Y1tY4fnGMHJ0"},"cell_type":"markdown","source":["Representaremos cada palabra en un idioma como un vector de un solo calor, o un vector gigante de ceros, excepto uno solo (en el índice de la palabra). En comparación con las docenas de caracteres que pueden existir en un idioma, hay muchas más palabras, por lo que el vector de codificación es mucho más grande. Sin embargo, haremos trampa un poco y recortaremos los datos para usar solo unos pocos miles de palabras por idioma.\n","\n","\n","\n"]},{"metadata":{"_uuid":"c6cc32378bbd59fc63c7b3f55c55078e80c82c5e","id":"SP22cgJOMHJ1"},"cell_type":"markdown","source":["Necesitaremos un índice único por palabra para usar como entradas y objetivos de las redes más adelante. Para hacer un seguimiento de todo esto, usaremos una clase auxiliar llamada Lang que tiene diccionarios de índice de → de palabras (word2index) e índice → palabra (index2word), así como un recuento de cada palabra word2count para usar para luego reemplazar palabras raras.\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"40a8bd1a95b092458c706dcf2c53935aa48ef694","id":"zc1HuQGcMHKK","executionInfo":{"status":"ok","timestamp":1688736799994,"user_tz":240,"elapsed":8,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["SOS_token = 0\n","EOS_token = 1\n","\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"],"execution_count":5,"outputs":[]},{"metadata":{"_uuid":"b5a8dd02cc3e77f614b0a29c5777127e2a24c95e","id":"10tOrt61MHKL"},"cell_type":"markdown","source":["Los archivos están todos en Unicode, para simplificar, convertiremos los caracteres Unicode a ASCII, haremos todo en minúsculas y recortaremos la mayoría de los signos de puntuación.\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"937163fbe359e7df853b4a8c1d4633a0221a8885","id":"GZrfDyFwMHKL","executionInfo":{"status":"ok","timestamp":1688736799994,"user_tz":240,"elapsed":7,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["# Convierta una cadena Unicode en ASCII simple\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","# Minúsculas, recortar y quitar caracteres que no sean letras\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s"],"execution_count":6,"outputs":[]},{"metadata":{"_uuid":"9f26c6f7549b345f228d7373831a4717383974c2","id":"rYuIBwOJMHKL"},"cell_type":"markdown","source":["Para leer el archivo de datos dividiremos el archivo en líneas, y luego dividiremos las líneas en pares. Los archivos son todos de inglés → otro idioma, así que si queremos traducir de Otro idioma → inglés, agregué la bandera reverse para invertir los pares.\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"df03c45c49831dc2ad014df4a504426765cf082f","id":"YqLf-pnxMHKL","executionInfo":{"status":"ok","timestamp":1688736799994,"user_tz":240,"elapsed":6,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["def readLangs(lang1, lang2, reverse=False):\n","    print(\"Reading lines...\")\n","\n","    # Lee el archivo y divídalo en líneas\n","    lines = open('/content/drive/MyDrive/IASeg/DATASETS/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n","        read().strip().split('\\n')\n","\n","    # Divide cada línea en pares y normaliza\n","    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","\n","    # Pares inversos, crear instancias de Lang\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang(lang2)\n","        output_lang = Lang(lang1)\n","    else:\n","        input_lang = Lang(lang1)\n","        output_lang = Lang(lang2)\n","\n","    return input_lang, output_lang, pairs"],"execution_count":7,"outputs":[]},{"metadata":{"_uuid":"58c8a6d373a3371d4689641c86e8e355ce2e6fa6","id":"suPFsaUWMHKM"},"cell_type":"markdown","source":["Ya que hay un * montón * de oraciones de ejemplo y queremos entrenar\n","algo rápido, recortaremos el conjunto de datos a solo relativamente corto y\n","oraciones simples. Aquí la extensión máxima es de 10 palabras (que incluye\n","puntuación final) y estamos filtrando a oraciones que se traducen a\n","la forma \"i am\" o \"he is\", etc. (contabilizando los apóstrofos reemplazados\n","antes).\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"ecd7636f1154d22f92b426b8174bbc1ced028ea4","id":"wRnoAEZsMHKM","executionInfo":{"status":"ok","timestamp":1688736799994,"user_tz":240,"elapsed":6,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["MAX_LENGTH = 10\n","\n","eng_prefixes = (\n","    \"i am \", \"i m \",\n","    \"he is\", \"he s \",\n","    \"she is\", \"she s\",\n","    \"you are\", \"you re \",\n","    \"we are\", \"we re \",\n","    \"they are\", \"they re \"\n",")\n","\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH and \\\n","        p[1].startswith(eng_prefixes)\n","\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]"],"execution_count":8,"outputs":[]},{"metadata":{"_uuid":"e539014d1cb2cb3a57c9fa3d242182f00e3b7f09","id":"rtCmpNdiMHKM"},"cell_type":"markdown","source":["El proceso completo para preparar los datos es:\n","\n","-  Leer archivo de texto y dividir en líneas, dividir líneas en pares\n","-  Normalizar texto, filtrar por longitud y contenido\n","-  Hacer listas de palabras a partir de oraciones en pares\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"42e89d50f18d85e04cc4eeb8ddbb872660fb30e3","colab":{"base_uri":"https://localhost:8080/"},"id":"6BUptuN5MHKM","executionInfo":{"status":"ok","timestamp":1688736814115,"user_tz":240,"elapsed":14127,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"9334a58a-0151-4ab3-fee1-fff446528e8e"},"cell_type":"code","source":["def prepareData(lang1, lang2, reverse=False):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n","    print(\"Tenemos %s pares de frases\" % len(pairs))\n","    pairs = filterPairs(pairs)\n","    print(\"Recortando a %s pares de frases\" % len(pairs))\n","    print(\"Conteo de palabras...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Palabras contadas:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","\n","input_lang, output_lang, pairs = prepareData('eng', 'es', True)\n","print(random.choice(pairs))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading lines...\n","Tenemos 120614 pares de frases\n","Recortando a 7755 pares de frases\n","Conteo de palabras...\n","Palabras contadas:\n","es 4036\n","eng 2836\n","['estoy esperando una llamada .', 'i m waiting for a phone call .']\n"]}]},{"metadata":{"_uuid":"35448a710694e731fefed60118136370abbf11cf","id":"J8sOjr3RMHKM"},"cell_type":"markdown","source":["The Seq2Seq Model\n","=================\n","\n","Una red neuronal recurrente, o RNN, es una red que opera en una secuencia y utiliza su propia salida como entrada para los pasos posteriores.\n","\n","Una `red de secuencia a secuencia`__, o\n","red seq2seq, o `Encoder Decoder\n","red`__, es un modelo\n","que consta de dos RNN llamadas codificador y decodificador. El codificador lee\n","una secuencia de entrada y salidas de un solo vector, y el decodificador lee\n","ese vector para producir una secuencia de salida.\n","\n","\n","A diferencia de la predicción de secuencias con un solo RNN, donde cada entrada\n","Corresponde a una salida, el modelo seq2seq nos libera de la secuencia\n","longitud y orden, lo que lo hace ideal para la traducción entre dos\n","Idiomas.\n","\n","Considere la frase \"I'm not the black cat\" → \"Yo no soy el\n","gato negro\". La mayoría de las palabras en la oración de entrada tienen un\n","traducción en la oración de salida, pero están en ligeramente diferente\n","órdenes, por ejemplo, \"Chat Noir\" y \"Black Cat\". Debido al \"ne/pas\"\n","Construcción También hay una palabra más en la oración de entrada. Sería\n","ser difícil producir una traducción correcta directamente de la secuencia\n","de palabras de entrada.\n","\n","Con un modelo seq2seq el codificador crea un único vector que, en el\n","caso ideal, codifica el \"significado\" de la secuencia de entrada en un solo\n","vector — un solo punto en algún espacio de oraciones de N dimensiones.\n","\n","\n"]},{"metadata":{"_uuid":"98703e7a6a7a6d761f9b51162b800aa6b96c2754","id":"qTs1VvKDMHKM"},"cell_type":"markdown","source":["Encoder\n","-----------\n","\n","El codificador de una red seq2seq es un RNN que genera algún valor para cada palabra de la oración de entrada. Para cada palabra de entrada, el codificador genera un vector y un estado oculto, y utiliza el estado oculto para la siguiente palabra de entrada.\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"f2c00be0d5acde2d9e3bb27845b67df209eb9128","id":"4qFFlu0NMHKN","executionInfo":{"status":"ok","timestamp":1688736814117,"user_tz":240,"elapsed":29,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size) #mapear\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":10,"outputs":[]},{"metadata":{"_uuid":"b9dfeab44ade50c9b7b10c947c52f099ff5f183f","id":"Gc7bdqc_MHKN"},"cell_type":"markdown","source":["Decoder\n","-----------\n","\n","El decodificador es otro RNN que toma los vectores de salida del codificador y genera una secuencia de palabras para crear la traducción.\n","\n","\n","\n"]},{"metadata":{"_uuid":"ce3c015f6dc78b455cd2fd0f0814dc6f30bd8223","id":"j47B3_rYMHKN"},"cell_type":"markdown","source":["\n","\n","En el decodificador seq2seq más simple usamos solo la última salida del codificador. Esta última salida a veces se denomina vector de contexto, ya que codifica el contexto de toda la secuencia. Este vector de contexto se utiliza como el estado oculto inicial del decodificador.\n","\n","En cada paso de la decodificación, el decodificador recibe un token de entrada y un estado oculto. El token de entrada inicial es el token de inicio de cadena <SOS> , y el primer estado oculto es el vector de contexto (el último estado oculto del codificador).\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"b657886bd7765be31b1af3c309bc2e4a004e59dd","id":"l_GVazqAMHKN","executionInfo":{"status":"ok","timestamp":1688736814118,"user_tz":240,"elapsed":28,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","        output = self.embedding(input).view(1, 1, -1)\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.softmax(self.out(output[0]))\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":11,"outputs":[]},{"metadata":{"_uuid":"aade1ec6764e0c91048529a760b19878e2c0fe19","id":"AnoAqKLGMHKO"},"cell_type":"markdown","source":["Attention Decoder\n","========================\n","Si solo se pasa el vector de contexto entre el codificador y el decodificador, ese vector único lleva la carga de codificar toda la oración.\n","\n","La atención permite que la red del decodificador se \"enfoque\" en una parte diferente de\n","Las salidas del codificador para cada paso de las propias salidas del decodificador. Primero\n","Calculamos un conjunto de *pesos de atención*. Estos se multiplicarán por\n","El codificador emite vectores para crear una combinación ponderada. El resultado\n","(denominado ''attn_applied'' en el código) debe contener información acerca de\n","esa parte específica de la secuencia de entrada, y así ayudar al decodificador\n","Elija las palabras de salida correctas.\n","\n","\n","El cálculo de los pesos de atención se realiza con otro feed-forward\n","capa ''attn'', utilizando la entrada del decodificador y el estado oculto como entradas.\n","Debido a que hay oraciones de todos los tamaños en los datos de entrenamiento, para\n","En realidad crear y entrenar esta capa tenemos que elegir un máximo\n","longitud de oración (longitud de entrada, para salidas de codificador) que puede aplicar\n","Para. Las oraciones de la longitud máxima usarán todos los pesos de atención,\n","mientras que las oraciones más cortas solo usarán las primeras.\n","\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"2c04793035e53e4fa92d24672c0dbea0443f7351","id":"pAshu2RmMHKO","executionInfo":{"status":"ok","timestamp":1688736814120,"user_tz":240,"elapsed":28,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            F.relu(self.attn(torch.cat((embedded[0], hidden[0]), 1))), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":12,"outputs":[]},{"metadata":{"_uuid":"ebccbd3b86e885468046901853f687738aba5095","id":"MVxZHXoQMHKO"},"cell_type":"markdown","source":["<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n","  limitation by using a relative position approach. Read about \"local\n","  attention\" in `Effective Approaches to Attention-based Neural Machine\n","  Translation <https://arxiv.org/abs/1508.04025>`__.</p></div>\n","\n","Training\n","========\n","\n","Preparing Training Data\n","-----------------------\n","\n","Para entrenar, para cada par necesitaremos un tensor de entrada (índices de las palabras en la oración de entrada) y un tensor objetivo (índices de las palabras en la oración objetivo). Al crear estos vectores, agregaremos el token EOS a ambas secuencias.\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"1eb68ec3b718a6d97472e81c2f47c381e6c6b32e","id":"QXhih-nrMHKO","executionInfo":{"status":"ok","timestamp":1688736814121,"user_tz":240,"elapsed":28,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)"],"execution_count":13,"outputs":[]},{"metadata":{"_uuid":"9e448dc6aa790780779b8616615c89df1e76a315","id":"syDKgYvtMHKP"},"cell_type":"markdown","source":["Training the Model\n","------------------\n","\n","Para entrenar, ejecutamos la oración de entrada a través del codificador y realizamos un seguimiento de cada salida y el último estado oculto. A continuación, el decodificador recibe el token como su `<SOS>` primera entrada, y el último estado oculto del codificador como su primer estado oculto.\n","\n","\n","\"Forzar a los maestros\" es el concepto de utilizar los resultados objetivo reales como\n","cada entrada siguiente, en lugar de usar la suposición del decodificador como la siguiente entrada.\n","El uso de la fuerza del maestro hace que converja más rápido, pero 'cuando el entrenado\n","La red es explotada, puede exhibir\n","inestabilidad <http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf>`__.\n","\n","Puede observar los resultados de las redes forzadas por el profesor que leen con\n","gramática coherente pero vagar lejos de la traducción correcta -\n","intuitivamente ha aprendido a representar la gramática de salida y puede \"elegir\n","arriba\" el significado una vez que el maestro le dice las primeras palabras, pero\n","no ha aprendido correctamente cómo crear la oración a partir de la traducción\n","en primer lugar.\n","\n","Debido a la libertad que nos da el autograd de PyTorch, podemos\n","Elija usar Teacher Forzar o no con una simple declaración IF. Giro\n","``teacher_forcing_ratio`` hasta usar más.\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"a8f49c6934f831c5241fd4bb16effc2395dca004","id":"BOGsq6JEMHKP","executionInfo":{"status":"ok","timestamp":1688736814122,"user_tz":240,"elapsed":29,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["teacher_forcing_ratio = 0.5\n","\n","\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"],"execution_count":14,"outputs":[]},{"metadata":{"_uuid":"d6f665aaebcf00aca44da8e3159199d8340f7fab","id":"FUrkN8VnMHKP"},"cell_type":"markdown","source":["Esta es una función auxiliar para imprimir el tiempo transcurrido y el tiempo restante estimado dado el tiempo actual y el porcentaje de progreso\n","\n"]},{"metadata":{"trusted":true,"_uuid":"c7748638d2bec50da176509a8f88cd4acd3ef253","id":"gA_b9zGAMHKP","executionInfo":{"status":"ok","timestamp":1688736814123,"user_tz":240,"elapsed":28,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["import time\n","import math\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"execution_count":15,"outputs":[]},{"metadata":{"_uuid":"fe8c5092cf7a7db4f070ebb71043b319d3aeb7ef","id":"5nsS_GdZMHKP"},"cell_type":"markdown","source":["Todo el proceso de entrenamiento se ve así:\n","\n","-  Iniciar un temporizador\n","-  Inicializar optimizadores y criterios\n","-  Crear un conjunto de pares de entrenamiento\n","-  Iniciar matriz de pérdidas vacía para trazar\n","\n","Luego llamamos al tren muchas veces y ocasionalmente imprimimos el progreso (% de ejemplos, tiempo hasta ahora, tiempo estimado) y la pérdida promedio.\n","\n","\n"]},{"cell_type":"code","source":["checkpoint_iter = 5000  # Definir la frecuencia para guardar los checkpoints"],"metadata":{"id":"I2PQ5-tq9YTJ","executionInfo":{"status":"ok","timestamp":1688736814124,"user_tz":240,"elapsed":28,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f39d78a7b264f183a563747e0575ad1d144a8f07","id":"I5OLJRnCMHKP","executionInfo":{"status":"ok","timestamp":1688736814125,"user_tz":240,"elapsed":28,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["import os\n","\n","\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(random.choice(pairs))\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    checkpoint_file = '/content/drive/MyDrive/IASeg/CheckpointsS2S/checkpoint.pt'\n","\n","    if os.path.exists(checkpoint_file):\n","        checkpoint = torch.load(checkpoint_file)  # Cargar el checkpoint previo\n","\n","        encoder.load_state_dict(checkpoint['encoder_state_dict'])\n","        decoder.load_state_dict(checkpoint['decoder_state_dict'])\n","        encoder_optimizer.load_state_dict(checkpoint['encoder_optimizer_state_dict'])\n","        decoder_optimizer.load_state_dict(checkpoint['decoder_optimizer_state_dict'])\n","        iter = checkpoint['iter']\n","        loss = checkpoint['loss']\n","    else:\n","        checkpoint = None\n","        iter = 1\n","        loss = 0\n","\n","\n","    for iter in range(iter, n_iters + 1):\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","\n","        loss = train(input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n","\n","        if iter % checkpoint_iter == 0:\n","            if checkpoint is not None:  # Check if checkpoint is assigned\n","                torch.save(checkpoint, f'/content/drive/MyDrive/IASeg/CheckpointsS2S/checkpoint_{iter}.pt')\n","\n","            checkpoint = {\n","                'encoder_state_dict': encoder.state_dict(),\n","                'decoder_state_dict': decoder.state_dict(),\n","                'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n","                'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n","                'loss': loss,\n","                'iter': iter,\n","                # Otras variables que desees guardar\n","            }\n","            # torch.save(checkpoint, f'checkpoint_{iter}.pt')\n","\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    if checkpoint is not None:  # Save the final checkpoint after the last iteration\n","        torch.save(checkpoint, f'/content/drive/MyDrive/IASeg/CheckpointsS2S/checkpoint.pt')\n","\n","    showPlot(plot_losses)"],"execution_count":17,"outputs":[]},{"metadata":{"_uuid":"eef23e82db773d2062cb0150eac0c9a924f72ea7","id":"69Pyp4zmMHKQ"},"cell_type":"markdown","source":["Trazar resultados\n","----------------\n","\n","El trazado se realiza con matplotlib, utilizando la matriz de valores de pérdida\n","''plot_losses'' guardado durante el entrenamiento.\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"9cb75c873c181951a2e943a52677fe5a8055a486","id":"aKBK1sLnMHKQ","executionInfo":{"status":"ok","timestamp":1688736814125,"user_tz":240,"elapsed":28,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"],"execution_count":18,"outputs":[]},{"metadata":{"_uuid":"42c78c1f7d27e67a3e8f731c4a784af6d61e0c49","id":"8OQ4Gze0MHKQ"},"cell_type":"markdown","source":["Evaluación\n","==========\n","\n","La evaluación es casi lo mismo que la capacitación, pero no hay objetivos, por lo que\n","Simplemente alimentamos las predicciones del decodificador a sí mismo para cada paso.\n","Cada vez que predice una palabra la agregamos a la cadena de salida, y si\n","predice el token EOS que detenemos allí. También almacenamos los decodificadores\n","Salidas de atención para su visualización posterior.\n"]},{"metadata":{"trusted":true,"_uuid":"1d42a9084c8da525caa8cdb2d482eb0234aff651","id":"75t7vNVrMHKQ","executionInfo":{"status":"ok","timestamp":1688736814126,"user_tz":240,"elapsed":28,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            decoder_attentions[di] = decoder_attention.data\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di + 1]"],"execution_count":19,"outputs":[]},{"metadata":{"_uuid":"6a4362c076c90c1dad90cbeebf81bdca1c72b884","id":"RfCNXkTJMHKQ"},"cell_type":"markdown","source":["Podemos evaluar oraciones aleatorias del conjunto de entrenamiento e imprimir la entrada, el objetivo y la salida para hacer algunos juicios de calidad subjetivos:"]},{"metadata":{"trusted":true,"_uuid":"3f98ce08bd64294067449affa53196287f9192d7","id":"aVJTzw8MMHKR","executionInfo":{"status":"ok","timestamp":1688736814127,"user_tz":240,"elapsed":28,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')"],"execution_count":20,"outputs":[]},{"metadata":{"_uuid":"8b0db6a84994cabfc1ef437e6b7760ed2702b76f","id":"Xk0Cgk_rMHKW"},"cell_type":"markdown","source":["Entrenamiento y evaluación\n","=======================\n","\n","Con todas estas funciones auxiliares en su lugar (parece trabajo extra, pero\n","hace que sea más fácil ejecutar múltiples experimentos) en realidad podemos\n","Inicialice una red y comience a entrenar.\n","\n","Recuerde que las oraciones de entrada estaban muy filtradas. Para este pequeño\n","conjunto de datos podemos utilizar redes relativamente pequeñas de 256 nodos ocultos y un\n","una sola capa GRU. Después de unos 40 minutos en una CPU de MacBook obtendremos algunos\n","resultados razonables.\n","\n","\n",".. Nota::\n","   Si ejecuta este cuaderno puede entrenar, interrumpir el kernel,\n","   Evalúe y continúe la capacitación más tarde. Comente las líneas donde el\n","   el codificador y el decodificador se inicializan y vuelven a ejecutar ''trainIters''.\n","\n"]},{"metadata":{"trusted":true,"_uuid":"607e1ac9c22f100887d70ebfdb6869d5e9d13680","id":"w_Srp8UkMHKW","executionInfo":{"status":"ok","timestamp":1688736814127,"user_tz":240,"elapsed":27,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["device = \"cuda\""],"execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"799bb6af2415e487dd136b6ff1502852da71dafe","colab":{"base_uri":"https://localhost:8080/"},"id":"Nt94iy-KMHKW","executionInfo":{"status":"ok","timestamp":1688738210412,"user_tz":240,"elapsed":1396311,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"a825bfeb-7515-409d-dc3f-a2898de91bb4"},"cell_type":"code","source":["hidden_size = 256\n","encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["1m 33s (- 21m 43s) (5000 6%) 3.1290\n","3m 6s (- 20m 12s) (10000 13%) 2.4831\n","4m 37s (- 18m 28s) (15000 20%) 2.0803\n","6m 6s (- 16m 47s) (20000 26%) 1.7976\n","7m 38s (- 15m 16s) (25000 33%) 1.5395\n","9m 8s (- 13m 43s) (30000 40%) 1.3148\n","10m 40s (- 12m 12s) (35000 46%) 1.1817\n","12m 11s (- 10m 40s) (40000 53%) 1.0296\n","13m 42s (- 9m 8s) (45000 60%) 0.8927\n","15m 14s (- 7m 37s) (50000 66%) 0.8194\n","16m 45s (- 6m 5s) (55000 73%) 0.6952\n","18m 30s (- 4m 37s) (60000 80%) 0.6463\n","20m 4s (- 3m 5s) (65000 86%) 0.5575\n","21m 36s (- 1m 32s) (70000 93%) 0.4987\n","23m 7s (- 0m 0s) (75000 100%) 0.4501\n"]}]},{"metadata":{"trusted":true,"_uuid":"9c2c47dd27c261d3a81f79312af931cad8171fea","colab":{"base_uri":"https://localhost:8080/"},"id":"TkFP3ykcMHKW","executionInfo":{"status":"ok","timestamp":1688738210413,"user_tz":240,"elapsed":66,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"a00b79c2-6dcc-41ee-f958-d2960c92678a"},"cell_type":"code","source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["> juega bien al tenis .\n","= he is good at playing tennis .\n","< he is good at tennis . <EOS>\n","\n","> estoy muy avergonzado .\n","= i m too ashamed .\n","< i m very embarrassed . <EOS>\n","\n","> estoy fascinada .\n","= i m fascinated .\n","< i m fascinated . <EOS>\n","\n","> no soy bueno para el frances .\n","= i m not good at french .\n","< i m not good at french . <EOS>\n","\n","> el es un hombre comun .\n","= he s just an ordinary man .\n","< he s just an man man . <EOS>\n","\n","> no sabes nadar verdad ?\n","= you are not able to swim are you ?\n","< you are not able to to you ? <EOS>\n","\n","> soy de china .\n","= i am from china .\n","< i am from china . <EOS>\n","\n","> soy la mas alta de nuestra clase .\n","= i am the tallest in our class .\n","< i am the tallest in our class . <EOS>\n","\n","> tiene cincuenta y tantos anos .\n","= he s in his fifties .\n","< he is thirty two . <EOS>\n","\n","> me interesa el alpinismo .\n","= i am interested in mountain climbing .\n","< i am interested in mountain climbing . <EOS>\n","\n"]}]},{"metadata":{"_uuid":"a02941a883a62a8731c17a128f096e49f14bde90","id":"IxzuQDTEMHKW"},"cell_type":"markdown","source":["Visualizando la atención\n","---------------------\n","\n","Una propiedad útil del mecanismo de atención es su alta interpretabilidad\n","Salidas. Porque se utiliza para ponderar salidas de codificador específicas del\n","secuencia de entrada, podemos imaginar mirando hacia dónde se enfoca más la red\n","en cada paso de tiempo.\n","\n","Simplemente puede ejecutar ''plt.matshow (atenciones)'' para ver la salida de atención\n","se muestra como una matriz, con las columnas siendo pasos de entrada y filas siendo\n","Pasos de salida:\n","\n","\n"]},{"metadata":{"trusted":true,"_uuid":"c3bc09b35f31baf5e3e5cd457313c9728e6831cb","colab":{"base_uri":"https://localhost:8080/"},"id":"JfFwLg9rMHKX","executionInfo":{"status":"ok","timestamp":1688738211259,"user_tz":240,"elapsed":861,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"8686bf96-1815-4a72-a65a-1470db199549"},"cell_type":"code","source":["output_words, attentions = evaluate(\n","    encoder1, attn_decoder1, \"tengo demasiado frio .\")\n","plt.matshow(attentions.numpy())\n","output_words"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i', 'am', 'very', 'cold', '.', '<EOS>']"]},"metadata":{},"execution_count":24}]},{"metadata":{"_uuid":"0cc87c191d9a55700c62cce20c3f7562096e5111","id":"ji_HOyBzMHKX"},"cell_type":"markdown","source":["Para una mejor experiencia de visualización haremos el trabajo extra de añadir ejes y etiquetas:\n","\n"]},{"metadata":{"trusted":true,"_uuid":"78bb5f4b6382872bbdf0a6d9ca7c56a6f2c9d47d","colab":{"base_uri":"https://localhost:8080/"},"id":"32oXRx2EMHKX","executionInfo":{"status":"ok","timestamp":1688738211260,"user_tz":240,"elapsed":15,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"05ea581a-00cc-4c57-f386-9cc9b863c3a9"},"cell_type":"code","source":["def showAttention(input_sentence, output_words, attentions):\n","    # Set up figure with colorbar\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(attentions.numpy(), cmap='bone')\n","    fig.colorbar(cax)\n","\n","    # Set up axes\n","    ax.set_xticklabels([''] + input_sentence.split(' ') +\n","                       ['<EOS>'], rotation=90)\n","    ax.set_yticklabels([''] + output_words)\n","\n","    # Show label at every tick\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","\n","\n","def evaluateAndShowAttention(input_sentence):\n","    output_words, attentions = evaluate(\n","        encoder1, attn_decoder1, input_sentence)\n","    print('input =', input_sentence)\n","    print('output =', ' '.join(output_words))\n","    showAttention(input_sentence, output_words, attentions)\n","\n","\n","evaluateAndShowAttention(\"ella es cinco anos mas joven que yo .\")\n","\n","evaluateAndShowAttention(\"es demasiado pequeno .\")\n","\n","evaluateAndShowAttention(\"no temo morir .\")\n","\n","evaluateAndShowAttention(\"es un joven director talentoso .\")"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["input = ella es cinco anos mas joven que yo .\n","output = she s five years older than i am . <EOS>\n","input = es demasiado pequeno .\n","output = he s too dangerous . <EOS>\n","input = no temo morir .\n","output = i m not able . <EOS>\n","input = es un joven director talentoso .\n","output = he s a very good man . <EOS>\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-25-8b5881de891c>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n","  ax.set_xticklabels([''] + input_sentence.split(' ') +\n","<ipython-input-25-8b5881de891c>:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n","  ax.set_yticklabels([''] + output_words)\n"]}]},{"metadata":{"trusted":true,"_uuid":"b724d2ce24e1688e568e7db760df9b26d19154ff","_kg_hide-output":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"Yc7HqphXMHKX","executionInfo":{"status":"ok","timestamp":1688738216572,"user_tz":240,"elapsed":5320,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"75ac0f9e-729a-4995-d233-20bb71ee19eb"},"cell_type":"code","source":["!pip3 install pytorch-pretrained-bert"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.10/dist-packages (0.6.2)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.0.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.22.4)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.28.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (4.65.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2022.10.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->pytorch-pretrained-bert) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->pytorch-pretrained-bert) (16.0.6)\n","Requirement already satisfied: botocore<1.32.0,>=1.31.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (1.31.0)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\n","Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (0.6.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.4)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.0->boto3->pytorch-pretrained-bert) (2.8.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.0->boto3->pytorch-pretrained-bert) (1.16.0)\n"]}]},{"metadata":{"trusted":true,"_uuid":"4bbd8f160f13233c4b9aeb4c03d918fb6c63a471","id":"5d4uMOfdMHKY","executionInfo":{"status":"ok","timestamp":1688738217870,"user_tz":240,"elapsed":1304,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["import torch\n","from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n","\n","# Cargar tokenizador de modelo pre-entrenado (vocabulario)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Entrada tokenizada\n","text = \"Who was Jim Henson ? Jim Henson was a puppeteer\"\n","tokenized_text = tokenizer.tokenize(text)\n","\n","# Enmascara un token que intentaremos predecir con 'BertForMaskedLM'\n","masked_index = 6\n","tokenized_text[masked_index] = '[MASK]'\n","assert tokenized_text == ['who', 'was', 'jim', 'henson', '?', 'jim', '[MASK]', 'was', 'a', 'puppet', '##eer']\n","\n","# Convertir token en índices de vocabulario\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","\n","# Definir los índices de las frases A y B asociados a la 1ª y 2ª oración (ver artículo)\n","segments_ids = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n","\n","# Convert inputs to PyTorch tensors\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])"],"execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdfcea68cef89f63915c20de1cec7cf03ecca981","id":"cl0pUdjyMHKY","executionInfo":{"status":"ok","timestamp":1688738225452,"user_tz":240,"elapsed":7586,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["# Modelo pre-entrenado de carga (pesos)\n","model = BertModel.from_pretrained('bert-base-uncased')\n","model.eval()\n","\n","# Predecir entidades de estados ocultos para cada capa\n","encoded_layers, _ = model(tokens_tensor, segments_tensors)\n","\n","# Tenemos un estado oculto para cada una de las 12 capas en el modelo bert-base-uncased\n","assert len(encoded_layers) == 12"],"execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd38381905c27d3dc1bed70b3d2c16a901ed22cc","id":"15XBKlh1MHKY","executionInfo":{"status":"ok","timestamp":1688738234857,"user_tz":240,"elapsed":9416,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["# Modelo pre-entrenado de carga (pesos)\n","model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model.eval()\n","\n","# Predecir todos los tokens\n","predictions = model(tokens_tensor, segments_tensors)\n","\n","# confirmar que pudimos predecir 'Henson'\n","predicted_index = torch.argmax(predictions[0, masked_index]).item()\n","predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","assert predicted_token == 'henson'"],"execution_count":29,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34e1b7c9ecbd55a718b8c242b7aae9dd1fc56c27","colab":{"base_uri":"https://localhost:8080/"},"id":"r529pPjPMHKZ","executionInfo":{"status":"ok","timestamp":1688738234859,"user_tz":240,"elapsed":26,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"c88a3e62-6e13-4f45-e452-588fbf975df5"},"cell_type":"code","source":["print(encoded_layers[1].size())"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 11, 768])\n"]}]},{"metadata":{"trusted":true,"_uuid":"2bfa208048e45b81bd5f89c5b83bdeb7bdb6d314","colab":{"base_uri":"https://localhost:8080/"},"id":"h2AeAzwDMHKZ","executionInfo":{"status":"ok","timestamp":1688738234860,"user_tz":240,"elapsed":21,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"4b403f1f-ae8e-4967-cb5c-1e2f884f81dc"},"cell_type":"code","source":["print(_.size())"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 768])\n"]}]},{"metadata":{"trusted":true,"_uuid":"e754d92b39e7d2a1061d74d9afc7b21d58d7096e","id":"WyoEgtykMHKZ","executionInfo":{"status":"ok","timestamp":1688738234862,"user_tz":240,"elapsed":16,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["def swish(x):\n","    return x * torch.sigmoid(x)\n","\n","class BERTEncoder(BertForSequenceClassification):\n","    def __init__(self, config, num_labels=2):\n","        super(BERTEncoder, self).__init__(config, num_labels=num_labels)\n","        self.num_labels = num_labels\n","        self.bert = BertModel(config) #capa codificador de BERT\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(config.hidden_size, num_labels)\n","        self.apply(self.init_bert_weights)\n","\n","\n","\n","    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n","        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","        logits = swish(logits)\n","\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","            return loss\n","        else:\n","            return logits\n","\n","\n"],"execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c26b3803d2a62a763323c9a377b8dc684c860ab","id":"SgAs0uSDMHKZ","executionInfo":{"status":"ok","timestamp":1688738250252,"user_tz":240,"elapsed":15405,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["model = BERTEncoder.from_pretrained('bert-base-uncased')\n","model.eval()\n","\n","# Predict all tokens\n","predictions = model(tokens_tensor)"],"execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"4f8e6638b28a84548e425ac8b59ff8382a60ed7d","colab":{"base_uri":"https://localhost:8080/"},"id":"DFvNLrQFMHKa","executionInfo":{"status":"ok","timestamp":1688738250253,"user_tz":240,"elapsed":74,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"cd376242-042f-424c-c22d-7e5d47c1a945"},"cell_type":"code","source":["print(predictions.size())"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 2])\n"]}]},{"cell_type":"code","source":["device = \"cuda\""],"metadata":{"id":"T1RIX3JZDyR1","executionInfo":{"status":"ok","timestamp":1688738250255,"user_tz":240,"elapsed":40,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf9c73e9a2be34eae5e91dad37d47013716b2a70","id":"SkQR9TC1MHKb","executionInfo":{"status":"ok","timestamp":1688738250256,"user_tz":240,"elapsed":40,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["# hidden_size = 256\n","# enc = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=hidden_size).to(device)\n","# for param in enc.bert.parameters():\n","#     param.requires_grad = False\n","# decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)"],"execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51dc184464d841791ca19062d9cd734f25c64c3b","id":"z5FMf2MWMHKb","executionInfo":{"status":"ok","timestamp":1688738250256,"user_tz":240,"elapsed":40,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["teacher_forcing_ratio = 0.5\n","\n","\n","def trainBert(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    #encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    encoder_hidden = encoder(input_tensor)\n","\n","    encoder_hidden = encoder_hidden.unsqueeze(0)\n","\n","    #for ei in range(input_length):\n","        #encoder_output, encoder_hidden = encoder(\n","            #input_tensor[ei], encoder_hidden)\n","        #encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"],"execution_count":42,"outputs":[]},{"cell_type":"code","source":["checkpoint_iter = 5000  # Definir la frecuencia para guardar los checkpoints"],"metadata":{"id":"cXZdMHtOJlFa","executionInfo":{"status":"ok","timestamp":1688738250256,"user_tz":240,"elapsed":39,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"execution_count":43,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e60c043bf9f688707fae9ed1fbf66a4a7777c50","id":"4gjxA0SbMHKc","executionInfo":{"status":"ok","timestamp":1688738250257,"user_tz":240,"elapsed":39,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["import os\n","\n","def trainItersBert(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01, mom=0):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate, momentum=mom)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate, momentum=mom)\n","\n","    #encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate, amsgrad=True)\n","    #encoder_scheduler = optim.lr_scheduler.CosineAnnealingLR(encoder_optimizer, n_iters)\n","    #decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate, amsgrad=True)\n","    #decoder_scheduler = optim.lr_scheduler.CosineAnnealingLR(decoder_optimizer, n_iters)\n","\n","    training_pairs = [tensorsFromPair(random.choice(pairs))\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    checkpoint_file = '/content/drive/MyDrive/IASeg/CheckpointsBERT/checkpoint.pt'\n","\n","    if os.path.exists(checkpoint_file):\n","        checkpoint = torch.load(checkpoint_file)  # Cargar el checkpoint previo\n","\n","        encoder.load_state_dict(checkpoint['encoder_state_dict'])\n","        decoder.load_state_dict(checkpoint['decoder_state_dict'])\n","        encoder_optimizer.load_state_dict(checkpoint['encoder_optimizer_state_dict'])\n","        decoder_optimizer.load_state_dict(checkpoint['decoder_optimizer_state_dict'])\n","        iter = checkpoint['iter']\n","        loss = checkpoint['loss']\n","        print(iter)\n","    else:\n","        checkpoint = None\n","        iter = 1\n","        loss = 0\n","\n","    for iter in range(iter, n_iters + 1):\n","        #encoder_scheduler.step()\n","        #decoder_scheduler.step()\n","\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","        input_tensor.transpose_(0,1)\n","        #print(input_tensor.size())\n","\n","        loss = trainBert(input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n","\n","        if iter % checkpoint_iter == 0:\n","            if checkpoint is not None:  # Check if checkpoint is assigned\n","                torch.save(checkpoint, f'/content/drive/MyDrive/IASeg/CheckpointsBERT/checkpoint_{iter}.pt')\n","\n","            checkpoint = {\n","                'encoder_state_dict': encoder.state_dict(),\n","                'decoder_state_dict': decoder.state_dict(),\n","                'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n","                'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n","                'loss': loss,\n","                'iter': iter,\n","                # Otras variables que desees guardar\n","            }\n","\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","\n","    if checkpoint is not None:  # Save the final checkpoint after the last iteration\n","        torch.save(checkpoint, f'/content/drive/MyDrive/IASeg/CheckpointsBERT/checkpoint.pt')\n","\n","    showPlot(plot_losses)"],"execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"027a6413a78d1aac6955f6629b1e9dc2480ecdc8","id":"hJ8T99IRMHKc","executionInfo":{"status":"ok","timestamp":1688738259570,"user_tz":240,"elapsed":9350,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["seq = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=hidden_size)"],"execution_count":46,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57c70b5f1745511d74b1810f1f7d499193810021","id":"tUhsNdEOMHKc","executionInfo":{"status":"ok","timestamp":1688738259571,"user_tz":240,"elapsed":53,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["out = seq(tokens_tensor)"],"execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbbfd2b7fb07ac5d52406ac0e3551e104f1f45b2","id":"9DQuxae3MHKd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688738259572,"user_tz":240,"elapsed":49,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"fbb290e1-7f62-401d-becb-06211b877c3c"},"cell_type":"code","source":["print(out.size())"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 256])\n"]}]},{"metadata":{"trusted":true,"_uuid":"cba7f1ba9f434b67ac8590d2ca26d968ef956615","id":"Lk_hXikTMHKd","executionInfo":{"status":"ok","timestamp":1688738259573,"user_tz":240,"elapsed":40,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["hidden_size = 256\n","decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)"],"execution_count":50,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f19c0f980381d3d71f37a81b6eabf3a3868a3a06","id":"4GyBgQ7MMHKd","executionInfo":{"status":"ok","timestamp":1688738279245,"user_tz":240,"elapsed":19710,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["enc2 = BERTEncoder.from_pretrained('bert-base-multilingual-cased', num_labels=hidden_size).to(device)\n","for param in enc2.bert.parameters():\n","    param.requires_grad = False"],"execution_count":51,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38900de78dfda67c88d6890e3fe6c4572bd2b3fe","id":"Mkus4aaMMHKe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688740567339,"user_tz":240,"elapsed":2288137,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"3fddf1ed-946b-4dfd-c052-f7ae7819f257"},"cell_type":"code","source":["trainItersBert(enc2, decoder1, 75000, print_every=500, learning_rate=0.01, mom=0.001)"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["0m 19s (- 48m 46s) (500 0%) 3.7123\n","0m 36s (- 44m 40s) (1000 1%) 3.4998\n","0m 49s (- 40m 28s) (1500 2%) 3.4420\n","1m 2s (- 38m 15s) (2000 2%) 3.3773\n","1m 16s (- 37m 4s) (2500 3%) 3.3066\n","1m 29s (- 35m 58s) (3000 4%) 3.2453\n","1m 43s (- 35m 9s) (3500 4%) 3.1833\n","1m 58s (- 34m 56s) (4000 5%) 3.2159\n","2m 11s (- 34m 22s) (4500 6%) 3.2792\n","2m 25s (- 33m 52s) (5000 6%) 3.1936\n","2m 40s (- 33m 42s) (5500 7%) 3.1970\n","2m 53s (- 33m 14s) (6000 8%) 3.1470\n","3m 6s (- 32m 47s) (6500 8%) 3.1756\n","3m 20s (- 32m 24s) (7000 9%) 3.1036\n","3m 33s (- 32m 4s) (7500 10%) 3.0973\n","3m 47s (- 31m 44s) (8000 10%) 3.0809\n","4m 9s (- 32m 28s) (8500 11%) 3.0854\n","4m 22s (- 32m 6s) (9000 12%) 3.1048\n","4m 36s (- 31m 46s) (9500 12%) 3.0044\n","4m 54s (- 31m 55s) (10000 13%) 3.0718\n","5m 9s (- 31m 42s) (10500 14%) 3.0231\n","5m 24s (- 31m 29s) (11000 14%) 3.1279\n","5m 38s (- 31m 8s) (11500 15%) 3.0840\n","5m 52s (- 30m 48s) (12000 16%) 3.0812\n","6m 6s (- 30m 33s) (12500 16%) 2.9942\n","6m 20s (- 30m 13s) (13000 17%) 3.0361\n","6m 33s (- 29m 54s) (13500 18%) 3.0740\n","6m 47s (- 29m 36s) (14000 18%) 2.9921\n","7m 0s (- 29m 16s) (14500 19%) 2.9724\n","7m 17s (- 29m 9s) (15000 20%) 2.9591\n","7m 32s (- 28m 56s) (15500 20%) 2.9440\n","7m 46s (- 28m 41s) (16000 21%) 3.0070\n","8m 0s (- 28m 22s) (16500 22%) 2.9285\n","8m 13s (- 28m 4s) (17000 22%) 2.9701\n","8m 27s (- 27m 46s) (17500 23%) 2.9317\n","8m 40s (- 27m 28s) (18000 24%) 3.0094\n","8m 53s (- 27m 10s) (18500 24%) 2.9565\n","9m 7s (- 26m 52s) (19000 25%) 2.9545\n","9m 20s (- 26m 35s) (19500 26%) 2.9502\n","9m 36s (- 26m 26s) (20000 26%) 2.9446\n","9m 51s (- 26m 12s) (20500 27%) 2.9394\n","10m 7s (- 26m 2s) (21000 28%) 2.9564\n","10m 29s (- 26m 6s) (21500 28%) 2.9211\n","10m 43s (- 25m 49s) (22000 29%) 2.9903\n","10m 56s (- 25m 31s) (22500 30%) 2.9043\n","11m 12s (- 25m 19s) (23000 30%) 2.9973\n","11m 25s (- 25m 3s) (23500 31%) 2.9011\n","11m 40s (- 24m 49s) (24000 32%) 2.9608\n","11m 54s (- 24m 32s) (24500 32%) 2.9213\n","12m 18s (- 24m 36s) (25000 33%) 2.9793\n","12m 32s (- 24m 21s) (25500 34%) 2.9031\n","12m 48s (- 24m 7s) (26000 34%) 2.8627\n","13m 1s (- 23m 50s) (26500 35%) 2.8891\n","13m 16s (- 23m 35s) (27000 36%) 2.8593\n","13m 30s (- 23m 19s) (27500 36%) 2.8992\n","13m 44s (- 23m 3s) (28000 37%) 2.9437\n","14m 3s (- 22m 56s) (28500 38%) 2.8700\n","14m 17s (- 22m 39s) (29000 38%) 2.8888\n","14m 32s (- 22m 25s) (29500 39%) 2.8652\n","14m 50s (- 22m 15s) (30000 40%) 2.7891\n","15m 5s (- 22m 0s) (30500 40%) 2.8740\n","15m 20s (- 21m 46s) (31000 41%) 2.8600\n","15m 33s (- 21m 29s) (31500 42%) 2.8110\n","15m 47s (- 21m 13s) (32000 42%) 2.8525\n","16m 1s (- 20m 57s) (32500 43%) 2.8793\n","16m 15s (- 20m 41s) (33000 44%) 2.8723\n","16m 29s (- 20m 25s) (33500 44%) 2.9161\n","16m 43s (- 20m 10s) (34000 45%) 2.8815\n","16m 57s (- 19m 54s) (34500 46%) 2.8858\n","17m 18s (- 19m 47s) (35000 46%) 2.9388\n","17m 33s (- 19m 32s) (35500 47%) 2.8458\n","17m 48s (- 19m 17s) (36000 48%) 2.7632\n","18m 3s (- 19m 3s) (36500 48%) 2.8354\n","18m 17s (- 18m 46s) (37000 49%) 2.8699\n","18m 30s (- 18m 30s) (37500 50%) 2.8617\n","18m 44s (- 18m 14s) (38000 50%) 2.6992\n","18m 57s (- 17m 58s) (38500 51%) 2.7840\n","19m 11s (- 17m 42s) (39000 52%) 2.7584\n","19m 24s (- 17m 26s) (39500 52%) 2.7717\n","19m 44s (- 17m 16s) (40000 53%) 2.7858\n","19m 59s (- 17m 1s) (40500 54%) 2.7592\n","20m 14s (- 16m 47s) (41000 54%) 2.7945\n","20m 27s (- 16m 31s) (41500 55%) 2.6826\n","20m 41s (- 16m 15s) (42000 56%) 2.7908\n","20m 54s (- 15m 59s) (42500 56%) 2.6422\n","21m 8s (- 15m 43s) (43000 57%) 2.8128\n","21m 21s (- 15m 28s) (43500 57%) 2.8560\n","21m 34s (- 15m 12s) (44000 58%) 2.7010\n","21m 48s (- 14m 56s) (44500 59%) 2.8679\n","22m 11s (- 14m 47s) (45000 60%) 2.7739\n","22m 29s (- 14m 35s) (45500 60%) 2.8636\n","22m 46s (- 14m 21s) (46000 61%) 2.7429\n","23m 0s (- 14m 5s) (46500 62%) 2.6646\n","23m 14s (- 13m 50s) (47000 62%) 2.7351\n","23m 27s (- 13m 35s) (47500 63%) 2.8349\n","23m 41s (- 13m 19s) (48000 64%) 2.7156\n","23m 54s (- 13m 3s) (48500 64%) 2.7183\n","24m 8s (- 12m 48s) (49000 65%) 2.7661\n","24m 22s (- 12m 33s) (49500 66%) 2.7812\n","24m 43s (- 12m 21s) (50000 66%) 2.6281\n","24m 58s (- 12m 7s) (50500 67%) 2.7280\n","25m 12s (- 11m 51s) (51000 68%) 2.7944\n","25m 26s (- 11m 36s) (51500 68%) 2.7573\n","25m 40s (- 11m 21s) (52000 69%) 2.7584\n","25m 53s (- 11m 5s) (52500 70%) 2.7287\n","26m 8s (- 10m 51s) (53000 70%) 2.7872\n","26m 22s (- 10m 36s) (53500 71%) 2.7819\n","26m 36s (- 10m 20s) (54000 72%) 2.7847\n","26m 50s (- 10m 5s) (54500 72%) 2.6582\n","27m 20s (- 9m 56s) (55000 73%) 2.7354\n","27m 40s (- 9m 43s) (55500 74%) 2.7395\n","27m 55s (- 9m 28s) (56000 74%) 2.7928\n","28m 9s (- 9m 13s) (56500 75%) 2.7226\n","28m 24s (- 8m 58s) (57000 76%) 2.7095\n","28m 39s (- 8m 43s) (57500 76%) 2.6664\n","28m 53s (- 8m 28s) (58000 77%) 2.6651\n","29m 7s (- 8m 12s) (58500 78%) 2.7091\n","29m 22s (- 7m 57s) (59000 78%) 2.6850\n","29m 36s (- 7m 42s) (59500 79%) 2.7504\n","30m 4s (- 7m 31s) (60000 80%) 2.7059\n","30m 25s (- 7m 17s) (60500 80%) 2.7673\n","30m 40s (- 7m 2s) (61000 81%) 2.7233\n","30m 55s (- 6m 47s) (61500 82%) 2.7182\n","31m 9s (- 6m 32s) (62000 82%) 2.6770\n","31m 23s (- 6m 16s) (62500 83%) 2.7625\n","31m 37s (- 6m 1s) (63000 84%) 2.6847\n","31m 51s (- 5m 46s) (63500 84%) 2.6953\n","32m 5s (- 5m 30s) (64000 85%) 2.6648\n","32m 19s (- 5m 15s) (64500 86%) 2.5881\n","32m 41s (- 5m 1s) (65000 86%) 2.6482\n","32m 56s (- 4m 46s) (65500 87%) 2.6911\n","33m 10s (- 4m 31s) (66000 88%) 2.6138\n","33m 24s (- 4m 16s) (66500 88%) 2.6871\n","33m 38s (- 4m 1s) (67000 89%) 2.6316\n","33m 52s (- 3m 45s) (67500 90%) 2.7129\n","34m 6s (- 3m 30s) (68000 90%) 2.7108\n","34m 20s (- 3m 15s) (68500 91%) 2.6752\n","34m 34s (- 3m 0s) (69000 92%) 2.7200\n","34m 49s (- 2m 45s) (69500 92%) 2.7321\n","35m 7s (- 2m 30s) (70000 93%) 2.6433\n","35m 28s (- 2m 15s) (70500 94%) 2.5922\n","35m 42s (- 2m 0s) (71000 94%) 2.5939\n","35m 58s (- 1m 45s) (71500 95%) 2.6508\n","36m 13s (- 1m 30s) (72000 96%) 2.6904\n","36m 29s (- 1m 15s) (72500 96%) 2.6365\n","36m 43s (- 1m 0s) (73000 97%) 2.5599\n","36m 58s (- 0m 45s) (73500 98%) 2.6408\n","37m 13s (- 0m 30s) (74000 98%) 2.6384\n","37m 28s (- 0m 15s) (74500 99%) 2.6699\n","37m 51s (- 0m 0s) (75000 100%) 2.7287\n"]}]},{"metadata":{"trusted":true,"_uuid":"348edb44f1aab7c30ae2b0e3e0d0a04c13df5582","id":"HggoXe7NMHKe","executionInfo":{"status":"ok","timestamp":1688740567341,"user_tz":240,"elapsed":45,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":["def evaluate(encoder, decoder, sentence, tokenizer, max_length=10):\n","    with torch.no_grad():\n","        input_tokens = tokenizer.tokenize(sentence)\n","        input_indices = tokenizer.convert_tokens_to_ids(input_tokens)\n","        input_tensor = torch.tensor([input_indices], device=device)\n","        input_length = input_tensor.size(1)\n","        attention_mask = torch.tensor([[1] * input_length], device=device)\n","\n","        encoder_hidden = encoder(input_tensor, attention_mask=attention_mask)\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)\n","        decoder_hidden = encoder_hidden.unsqueeze(0)  # Agregar dimensión adiciona\n","\n","        decoded_words = []\n","\n","        for _ in range(max_length):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words"],"execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abe769c6ac16d7521ad88c11d5a85d5405d6ab6b","id":"FnJy4lB_MHKe","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1688740567341,"user_tz":240,"elapsed":18,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}},"outputId":"78c30d64-e161-431d-b640-88456eb80c4f"},"cell_type":"code","source":["output_words= evaluate(\n","    enc2, decoder1, \"no tengo miedo a morir .\",tokenizer)\n","# plt.matshow(attentions.numpy())\n","translation = ' '.join(output_words)\n","translation"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'i m not . . <EOS>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":54}]},{"metadata":{"trusted":true,"_uuid":"14a5529c314cc5c7cea6ff013f6b00fbfe117c36","id":"6ZVV33o8MHKe","executionInfo":{"status":"ok","timestamp":1688740567342,"user_tz":240,"elapsed":16,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":[],"execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ceebce934c0ab4c21558300eccc89c5b6415b78c","id":"OfttMkdZMHKe","executionInfo":{"status":"ok","timestamp":1688740567343,"user_tz":240,"elapsed":16,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":[],"execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72b221cbe14856e162840837c6d9e5e75d74a434","id":"9CfSNNzxMHKe","executionInfo":{"status":"ok","timestamp":1688740567344,"user_tz":240,"elapsed":16,"user":{"displayName":"Reynaldo Kama","userId":"10307645728185153937"}}},"cell_type":"code","source":[],"execution_count":54,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}