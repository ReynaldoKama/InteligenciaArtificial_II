{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg90deR13qYE"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/041_attention/attention.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kzp2jHl3qY7"
      },
      "source": [
        "# Mecanismos de Atención"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB_r5hooT7kU"
      },
      "source": [
        "## El *dataset*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AInMhCLQfZqK",
        "outputId": "420c5191-b7e2-4200-fc75-39ab8411de2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOBTPIplDqi7",
        "outputId": "d0d09113-142f-44b3-9bc7-8fb011858481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7jCpbPGOEL5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "A8riGRKJEX_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:52.733066Z",
          "start_time": "2020-09-04T12:31:52.725066Z"
        },
        "id": "TttrMAUPT7kV"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "def read_file(file, reverse=False):\n",
        "    # Read the file and split into lines\n",
        "    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n",
        "\n",
        "    return pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.087569Z",
          "start_time": "2020-09-04T12:31:56.074570Z"
        },
        "id": "lcgcmwOAT7kY"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "PAD_token = 2\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\"SOS\": 0, \"EOS\": 1, \"PAD\": 2}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\"}\n",
        "        self.n_words = 3  # Count SOS, EOS and PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    def indexesFromSentence(self, sentence):\n",
        "        return [self.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "    def sentenceFromIndex(self, index):\n",
        "        return [self.index2word[ix] for ix in index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXnmteciT7kZ"
      },
      "source": [
        "Para poder aplicar la capa de `attention` necesitamos que nuestras frases tengan una longitud máxima definida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.103564Z",
          "start_time": "2020-09-04T12:31:56.088570Z"
        },
        "id": "mn_55MaTT7kZ"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 768\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPairs(pairs, filters, lang=0):\n",
        "    return [p for p in pairs if p[lang].startswith(filters)]\n",
        "\n",
        "def trimPairs(pairs):\n",
        "    return [p for p in pairs if len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.717657Z",
          "start_time": "2020-09-04T12:31:56.104565Z"
        },
        "code_folding": [
          0
        ],
        "id": "BktiLQJtT7kZ",
        "outputId": "2da5516f-2d4d-4774-ce7d-61e85a6f7e43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tenemos 120614 pares de frases\n",
            "Tenemos 120614 pares de frases con longitud menor de 768\n",
            "Longitud vocabularios:\n",
            "spa 12990\n",
            "eng 24933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i have a big problem .', 'tengo un quilombo de novela .']"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "def prepareData(file, filters=None, reverse=False):\n",
        "    pairs = read_file(file, reverse)\n",
        "    print(f\"Tenemos {len(pairs)} pares de frases\")\n",
        "\n",
        "    if filters is not None:\n",
        "        pairs = filterPairs(pairs, filters, int(reverse))\n",
        "        print(f\"Filtramos a {len(pairs)} pares de frases\")\n",
        "\n",
        "    pairs = trimPairs(pairs)\n",
        "    print(f\"Tenemos {len(pairs)} pares de frases con longitud menor de {MAX_LENGTH}\")\n",
        "\n",
        "    if reverse:\n",
        "        input_lang = Lang('eng')\n",
        "        output_lang = Lang('spa')\n",
        "    else:\n",
        "        input_lang = Lang('spa')\n",
        "        output_lang = Lang('eng')\n",
        "\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "\n",
        "    print(\"Longitud vocabularios:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('/content/drive/MyDrive/FINAL/spa.txt')\n",
        "\n",
        "# descomentar para usar el dataset filtrado\n",
        "#input_lang, output_lang, pairs = prepareData('spa.txt', filters=eng_prefixes)\n",
        "\n",
        "random.choice(pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.730653Z",
          "start_time": "2020-09-04T12:31:59.719659Z"
        },
        "scrolled": true,
        "id": "jwYPWmNkT7ka"
      },
      "outputs": [],
      "source": [
        "# output_lang.indexesFromSentence('tengo mucha sed .')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.754653Z",
          "start_time": "2020-09-04T12:31:59.731654Z"
        },
        "id": "o6P5x5RzT7ka"
      },
      "outputs": [],
      "source": [
        "# output_lang.sentenceFromIndex([3, 1028, 647, 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrSUUnZGT7ka"
      },
      "source": [
        "En el `Dataset` nos aseguraremos de añadir el *padding* necesario para que todas las frases tengan la misma longitud, lo cual no hace necesario utilizar la función `collate` que implementamos en el post anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T08:13:53.670033Z",
          "start_time": "2020-09-04T08:13:53.652976Z"
        },
        "id": "FDPRTeKgT7kb"
      },
      "source": [
        "## El modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTncNHa9T7kc"
      },
      "source": [
        "En lo que se refiere al `encoder`, seguimos usando exactamente la misma arquitectura. La única diferencia es que, además del último estado oculto, necesitaremos todas sus salidas para que el `decoder` pueda usarlas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.421231Z",
          "start_time": "2020-09-04T12:32:01.406231Z"
        },
        "id": "3MIc5I91T7kc"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def forward(self, input_sentences, attention_mask):\n",
        "        outputs = self.bert(input_sentences, attention_mask=attention_mask)\n",
        "        encoder_outputs = outputs.last_hidden_state\n",
        "        print(encoder_outputs.size)\n",
        "        encoder_hidden = None  # No se utiliza en BERT\n",
        "        return encoder_outputs, encoder_hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKvJ28O-T7kc"
      },
      "source": [
        "### El *decoder* con *attention*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "# Cargar el modelo preentrenado de BERT\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_output_dim = model.config.hidden_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rILqohErkiqq",
        "outputId": "47d277e4-2023-4196-8bb6-6baed7448c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:43:51.447608Z",
          "start_time": "2020-09-04T13:43:51.433585Z"
        },
        "id": "THXw8128T7kd"
      },
      "outputs": [],
      "source": [
        "class AttnDecoder(torch.nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, n_layers, max_length):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers  # Agregar el atributo n_layers\n",
        "        self.hidden_size = hidden_size  # Agregar el atributo n_layers\n",
        "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
        "        self.out = torch.nn.Linear(hidden_size+bert_output_dim, input_size)\n",
        "\n",
        "        self.attn = torch.nn.Linear(hidden_size + embedding_size, max_length)\n",
        "        self.attn_combine = torch.nn.Linear(hidden_size * 2, hidden_size)\n",
        "\n",
        "    def forward(self, input_words, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input_words)\n",
        "\n",
        "        attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs.transpose(1, 2))\n",
        "\n",
        "        output = torch.cat((embedded.squeeze(1), attn_applied.squeeze(1)), 1)\n",
        "        output = self.attn_combine(output)\n",
        "        output = torch.nn.functional.relu(output)\n",
        "\n",
        "        output, hidden = self.rnn(output.unsqueeze(1), hidden)\n",
        "        output = self.out(output.squeeze(1))\n",
        "\n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Crear un nuevo objeto de clase Dataset para utilizar el tokenizador de BERT\n",
        "class BERTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        input_sentence = self.pairs[ix][0]\n",
        "        output_sentence = self.pairs[ix][1]\n",
        "\n",
        "        # Tokenizar las oraciones de entrada y salida\n",
        "        input_tokens = tokenizer.encode(input_sentence, add_special_tokens=True)\n",
        "        output_tokens = tokenizer.encode(output_sentence, add_special_tokens=True)\n",
        "\n",
        "        return torch.tensor(input_tokens), torch.tensor(output_tokens)"
      ],
      "metadata": {
        "id": "R-Kg5EudErzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    input_sentences, output_sentences = zip(*batch)\n",
        "    input_sentences = pad_sequence(input_sentences, batch_first=True)\n",
        "    output_sentences = pad_sequence(output_sentences, batch_first=True)\n",
        "    return input_sentences, output_sentences"
      ],
      "metadata": {
        "id": "wk02BxNSGOLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(pairs) * 80 // 100\n",
        "train_pairs = pairs[:train_size]\n",
        "test_pairs = pairs[train_size:]\n",
        "\n",
        "train_dataset = BERTDataset(train_pairs)\n",
        "test_dataset = BERTDataset(test_pairs)\n",
        "\n",
        "batch_size = 64\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "h4_Dw1TlEwRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "# Cargar el modelo preentrenado de BERT\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Obtener el tamaño del espacio oculto\n",
        "hidden_size = model.config.hidden_size\n",
        "\n",
        "# Obtener el tamaño del vocabulario\n",
        "vocab_size = model.config.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsLRZl7yVCBX",
        "outputId": "ba049c18-8609-4f63-c67f-09121330d39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder()\n",
        "decoder = AttnDecoder(vocab_size, hidden_size, hidden_size, n_layers=2, max_length=MAX_LENGTH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7zM7ccgE5Mq",
        "outputId": "fa032192-41d9-4c05-fbb9-a4a6bff5b5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el dispositivo de entrenamiento\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Mover los modelos al dispositivo de entrenamiento\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKFQ60P3Fc9r",
        "outputId": "4913d59a-6566-4c85-8226-907023f54ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttnDecoder(\n",
              "  (embedding): Embedding(30522, 768)\n",
              "  (rnn): GRU(768, 768, num_layers=2, batch_first=True)\n",
              "  (out): Linear(in_features=1536, out_features=30522, bias=True)\n",
              "  (attn): Linear(in_features=1536, out_features=768, bias=True)\n",
              "  (attn_combine): Linear(in_features=1536, out_features=768, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los optimizadores y la función de pérdida\n",
        "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Función de entrenamiento\n",
        "def fit(encoder, decoder, dataloader, epochs=10):\n",
        "    for epoch in range(1, epochs+1):\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        train_loss = []\n",
        "        bar = tqdm(dataloader)\n",
        "        for input_sentences, output_sentences in bar:\n",
        "            bs = input_sentences.size(0)\n",
        "            loss = 0\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "\n",
        "            # Preparar los datos en el dispositivo de entrenamiento\n",
        "            input_sentences = input_sentences.to(device)\n",
        "            output_sentences = output_sentences.to(device)\n",
        "\n",
        "            # Generar la máscara de atención para el codificador\n",
        "            attention_mask = (input_sentences != 0).to(device)\n",
        "\n",
        "            # Obtener las salidas del codificador\n",
        "            encoder_outputs, _ = encoder(input_sentences, attention_mask)\n",
        "\n",
        "            # Inicializar el estado oculto del decodificador\n",
        "            decoder_hidden = torch.zeros(decoder.n_layers, bs, decoder.hidden_size).to(device)\n",
        "\n",
        "            # Iterar sobre las secuencias de salida\n",
        "            decoder_input = torch.tensor([[output_lang.word2index['SOS']] * bs], device=device).transpose(0, 1)\n",
        "            for i in range(output_sentences.size(1)):\n",
        "                output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "                loss += criterion(output, output_sentences[:, i])\n",
        "                decoder_input = output_sentences[:, i].unsqueeze(1)\n",
        "\n",
        "            # Retropropagación y optimización\n",
        "            loss.backward()\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            bar.set_description(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f}\")"
      ],
      "metadata": {
        "id": "YkIApXGhFuEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "fit(encoder, decoder, train_dataloader, epochs=10)"
      ],
      "metadata": {
        "id": "_3-3vzh0FjDL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "c568c52b-e953-4a58-837f-bbcd56102d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1508 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method size of Tensor object at 0x7f0be6757a10>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-176-92cc2031206f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Entrenar el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-161-ec2e95efc119>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(encoder, decoder, dataloader, epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SOS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-169-89183eeef0e1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_words, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_applied\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_combine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x780 and 1536x768)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbpHgPJPT7ke"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssehey0pT7ke"
      },
      "source": [
        "Vamos a implementar el bucle de entrenamiento. En primer lugar, al tener ahora dos redes neuronales, necesitaremos dos optimizadores (uno para el `encoder` y otro para el `decoder`). Al `encoder` le pasaremos la frase en el idioma original, y obtendremos el estado oculto final. Este estado oculto lo usaremos para inicializar el `decoder` que, junto al token `<sos>`, generará la primera palabra de la frase traducida. Repetiremos el proceso, utilizando como entrada la anterior salida del decoder, hasta obtener el token `<eos>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.593231Z",
          "start_time": "2020-09-04T12:32:01.579232Z"
        },
        "code_folding": [
          3
        ],
        "id": "b_OnuRZ2T7ke"
      },
      "outputs": [],
      "source": [
        "# from tqdm import tqdm\n",
        "# import numpy as np\n",
        "\n",
        "# def fit(encoder, decoder, dataloader, epochs=10):\n",
        "#     encoder.to(device)\n",
        "#     decoder.to(device)\n",
        "#     encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
        "#     decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
        "#     criterion = torch.nn.CrossEntropyLoss()\n",
        "#     for epoch in range(1, epochs+1):\n",
        "#         encoder.train()\n",
        "#         decoder.train()\n",
        "#         train_loss = []\n",
        "#         bar = tqdm(dataloader['train'])\n",
        "#         for batch in bar:\n",
        "#             input_sentences, output_sentences = batch\n",
        "#             bs = input_sentences.shape[0]\n",
        "#             loss = 0\n",
        "#             encoder_optimizer.zero_grad()\n",
        "#             decoder_optimizer.zero_grad()\n",
        "#             # obtenemos el último estado oculto del encoder\n",
        "#             encoder_outputs, hidden = encoder(input_sentences)\n",
        "#             # calculamos las salidas del decoder de manera recurrente\n",
        "#             decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
        "#             for i in range(output_sentences.shape[1]):\n",
        "#                 output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "#                 loss += criterion(output, output_sentences[:, i].view(bs))\n",
        "#                 # el siguiente input será la palabra predicha\n",
        "#                 decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
        "#             # optimización\n",
        "#             loss.backward()\n",
        "#             encoder_optimizer.step()\n",
        "#             decoder_optimizer.step()\n",
        "#             train_loss.append(loss.item())\n",
        "#             bar.set_description(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f}\")\n",
        "\n",
        "#         val_loss = []\n",
        "#         encoder.eval()\n",
        "#         decoder.eval()\n",
        "#         with torch.no_grad():\n",
        "#             bar = tqdm(dataloader['test'])\n",
        "#             for batch in bar:\n",
        "#                 input_sentences, output_sentences = batch\n",
        "#                 bs = input_sentences.shape[0]\n",
        "#                 loss = 0\n",
        "#                 # obtenemos el último estado oculto del encoder\n",
        "#                 encoder_outputs, hidden = encoder(input_sentences)\n",
        "#                 # calculamos las salidas del decoder de manera recurrente\n",
        "#                 decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
        "#                 for i in range(output_sentences.shape[1]):\n",
        "#                     output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "#                     loss += criterion(output, output_sentences[:, i].view(bs))\n",
        "#                     # el siguiente input será la palabra predicha\n",
        "#                     decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
        "#                 val_loss.append(loss.item())\n",
        "#                 bar.set_description(f\"Epoch {epoch}/{epochs} val_loss {np.mean(val_loss):.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:58:02.367102Z",
          "start_time": "2020-09-04T12:32:01.595236Z"
        },
        "id": "286N--CWT7ke"
      },
      "outputs": [],
      "source": [
        "# fit(encoder, decoder, dataloader, epochs=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO2g6NkYT7kf"
      },
      "source": [
        "## Generando traducciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxNmE7VIT7kf"
      },
      "source": [
        "Una vez tenemos nuestro modelo entrenado, podemos utilizarlo para traducir frases del inglés al castellano de la siguiente manera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:31.925887Z",
          "start_time": "2020-09-04T13:12:31.915888Z"
        },
        "id": "-YIV-bEpT7kf"
      },
      "outputs": [],
      "source": [
        "# input_sentence, output_sentence = dataset['train'][10]\n",
        "# input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:32.615887Z",
          "start_time": "2020-09-04T13:12:32.598887Z"
        },
        "code_folding": [],
        "id": "lG00JU1bT7kk"
      },
      "outputs": [],
      "source": [
        "# def predict(input_sentence):\n",
        "#     # obtenemos el último estado oculto del encoder\n",
        "#     encoder_outputs, hidden = encoder(input_sentence.unsqueeze(0))\n",
        "#     # calculamos las salidas del decoder de manera recurrente\n",
        "#     decoder_input = torch.tensor([[output_lang.word2index['SOS']]], device=device)\n",
        "#     # iteramos hasta que el decoder nos de el token <eos>\n",
        "#     outputs = []\n",
        "#     decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
        "#     i = 0\n",
        "#     while True:\n",
        "#         output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "#         decoder_attentions[i] = attn_weights.data\n",
        "#         i += 1\n",
        "#         decoder_input = torch.argmax(output, axis=1).view(1, 1)\n",
        "#         outputs.append(decoder_input.cpu().item())\n",
        "#         if decoder_input.item() == output_lang.word2index['EOS']:\n",
        "#             break\n",
        "#     return output_lang.sentenceFromIndex(outputs), decoder_attentions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:32.789887Z",
          "start_time": "2020-09-04T13:12:32.775888Z"
        },
        "id": "0G8aMh4GT7kk"
      },
      "outputs": [],
      "source": [
        "# output_words, attn = predict(input_sentence)\n",
        "# output_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP9C7CZiT7kk"
      },
      "source": [
        "## Visualización de atención"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5Mjo80HT7kl"
      },
      "source": [
        "Una de las ventajas que nos da la capa de atención es que nos permite visualizar en qué partes de los inputs se fija el modelo para generar cada una de las palabras en el output, dando un grado de explicabilidad a nuestro modelo (una propiedad siempre deseada en nuestro modelos de `Machine Learning`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:33.513889Z",
          "start_time": "2020-09-04T13:12:33.505889Z"
        },
        "id": "pXLH9U14T7kl"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.ticker as ticker\n",
        "\n",
        "# def showAttention(input_sentence, output_words, attentions):\n",
        "#     lim1, lim2 = input_sentence.index('EOS')+1, output_words.index('EOS')+1\n",
        "#     fig = plt.figure(dpi=100)\n",
        "#     ax = fig.add_subplot(111)\n",
        "#     cax = ax.matshow(attentions[:lim2, :lim1].numpy(), cmap='bone')\n",
        "#     fig.colorbar(cax)\n",
        "#     # Set up axes\n",
        "#     ax.set_xticklabels([' '] + input_sentence[:lim1], rotation=90)\n",
        "#     ax.set_yticklabels([' '] + output_words)\n",
        "#     # Show label at every tick\n",
        "#     ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "#     ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:34.273921Z",
          "start_time": "2020-09-04T13:12:34.160888Z"
        },
        "id": "qfnTRZGWT7kl"
      },
      "outputs": [],
      "source": [
        "# showAttention(input_lang.sentenceFromIndex(input_sentence.tolist()), output_words, attn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkxkoW97T7kl"
      },
      "source": [
        "## Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6m67KKzT7km"
      },
      "source": [
        "En este post hemos visto como introducir mecanismos de atención en nuestra arquitectura `encoder-decoder`, los cuales permiten a nuestra red neuronal focalizarse en partes concretas de los *inputs* a la hora de generar los *outputs*. Esta nueva capa no solo puede mejorar nuestros modelos sino que además también es interpretable, dándonos una idea del razonamiento detrás de las predicciones de nuestro modelo. Las redes neuronales con mejores prestaciones a día de hoy en tareas de `NLP`, los `transformers`, están basados enteramente en este tipo de capas de atención."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "233.594px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}